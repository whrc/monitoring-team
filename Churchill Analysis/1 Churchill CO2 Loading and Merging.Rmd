---
title: "Churchill CO2 Loading and Merging"
author: "Dani Trangmoe"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dev="png")

#add root directory here for github

```


# Load Data

### CA CF3 Partitioned Data

Using data from bucket for now, maybe switch to ameriflux data for continuity when it's available?

```{r, include=FALSE}
rm(list = ls())

library(data.table)
library(ggplot2)
library(cowplot)
library(openair)
library(plotrix)
library(signal)
library(svMisc)
library(zoo)
library(stringr)
library(plyr)
library(viridis)
library(lubridate)
library(tidyverse)
library(gridExtra)
library(plotly)
library(RColorBrewer)
```


```{r, warning=FALSE, echo=FALSE}
df3 = fread('C:/Users/dtrangmoe/Documents/Churchill/Data/CA_CF3.csv', na.strings="-9999")
```


Create usable timestamp variable

```{r, warning=FALSE, echo=FALSE}

df3$TIMESTAMP_END = as.character(df3$TIMESTAMP_END)
df3$TIMESTAMP_START = as.character(df3$TIMESTAMP_START)

df3$TIMESTAMP_END = as.POSIXct(df3$TIMESTAMP_END, tz="UTC", format = "%Y%m%d%H%M")
df3$TIMESTAMP_START = as.POSIXct(df3$TIMESTAMP_START, tz="UTC", format = "%Y%m%d%H%M")

```


### CA CF1 Partitioned Data


```{r, warning=FALSE, echo=FALSE}
df1 = fread('C:/Users/dtrangmoe/Documents/CA-CF1 FullSet/AMF_CA-CF1_FLUXNET_FULLSET_2007-2008_3-5/AMF_CA-CF1_FLUXNET_FULLSET_HH_2007-2008_3-5.csv', na.strings="-9999")
```


Create usable timestamp variables

```{r, warning=FALSE, echo=FALSE}

df1$TIMESTAMP_END = as.character(df1$TIMESTAMP_END)
df1$TIMESTAMP_START = as.character(df1$TIMESTAMP_START)

df1$TIMESTAMP_END = as.POSIXct(df1$TIMESTAMP_END, tz="UTC", format = "%Y%m%d%H%M")
df1$TIMESTAMP_START = as.POSIXct(df1$TIMESTAMP_START, tz="UTC", format = "%Y%m%d%H%M")


```


#### Cut QC=3 Data from CF1

Removes QC=3 data from poor quality gapfilling. Includes winter NEE data

```{r}
# switch to QC flag = 3 to filter winter data
# isolate each variable by their QC flag  

QCFlags <- grep("QC$", names(df1), value = TRUE)


for (col_QC in QCFlags) {
  
col_data <- gsub("\\_QC", "", col_QC)

df1[df1[[col_QC]] == 3, col_data] <- NA

}

```


# Remove unused variables

```{r}

## Remove data that won't be used, for easy merging

#Daytime partitioned data
df1 <- select(df1, !all_of(names(df1)[grep("_DT", names(df1))]))

df3 <- select(df3, !all_of(names(df3)[grep("_DT", names(df3))]))

#_TEST
df3 <- select(df3, !all_of(names(df3)[grep("_TEST$", names(df3))]))

#ERA biomet data
df1 <- select(df1, !all_of(names(df1)[grep("_ERA", names(df1))]))

#QC flags
df1 <- select(df1, !all_of(names(df1)[grep("_QC", names(df1))]))

#Random Uncertainty
df1 <- select(df1, !all_of(names(df1)[grep("RANDUNC", names(df1))]))

#Standard error
df1 <- select(df1, !all_of(names(df1)[grep("_SE", names(df1))]))

#_POT
df1 <- select(df1, !all_of(names(df1)[grep("_POT", names(df1))]))

#percentile corrections
df1 <- select(df1, !all_of(names(df1)[grep("_[0-9]{2}?", names(df1))]))

#USTAR50
df1 <- select(df1, !all_of(names(df1)[grep("USTAR50", names(df1))]))

#EBC
df1 <- select(df1, !all_of(names(df1)[grep("EBC", names(df1))]))

#JOINTUNC
df1 <- select(df1, !all_of(names(df1)[grep("JOINTUNC", names(df1))]))

#Mean
df1 <- select(df1, !all_of(names(df1)[grep("_MEAN$", names(df1))]))

#SHF- no data in this column
df1 <- select(df1, !all_of(names(df1)[grep("G_F_MDS", names(df1))]))
```

# Rename and Merge


Change soil temp names for consistency
```{r}
names(df3)[names(df3) == "TS_3_1_1"] <- "TS_2_0_1"
names(df3)[names(df3) == "TS_3_2_1"] <- "TS_2_05_1"
names(df3)[names(df3) == "TS_3_3_1"] <- "TS_2_1_1"
names(df3)[names(df3) == "TS_3_4_1"] <- "TS_2_2_1"
names(df3)[names(df3) == "TS_3_5_1"] <- "TS_2_3_1"
names(df3)[names(df3) == "TS_3_6_1"] <- "TS_2_4_1"
names(df3)[names(df3) == "TS_3_7_1"] <- "TS_2_5_1"
names(df3)[names(df3) == "TS_3_8_1"] <- "TS_2_6_1"
names(df3)[names(df3) == "TS_3_9_1"] <- "TS_2_7_1"
names(df3)[names(df3) == "TS_3_10_1"] <- "TS_2_8_1"
names(df3)[names(df3) == "TS_3_11_1"] <- "TS_2_9_1"
names(df3)[names(df3) == "TS_3_12_1"] <- "TS_2_10_1"

names(df3)[names(df3) == "TS_4_1_1"] <- "TS_1_0_1"
names(df3)[names(df3) == "TS_4_2_1"] <- "TS_1_05_1"
names(df3)[names(df3) == "TS_4_3_1"] <- "TS_1_1_1"
names(df3)[names(df3) == "TS_4_4_1"] <- "TS_1_2_1"
names(df3)[names(df3) == "TS_4_5_1"] <- "TS_1_3_1"
names(df3)[names(df3) == "TS_4_6_1"] <- "TS_1_4_1"
names(df3)[names(df3) == "TS_4_7_1"] <- "TS_1_5_1"
names(df3)[names(df3) == "TS_4_8_1"] <- "TS_1_6_1"
names(df3)[names(df3) == "TS_4_9_1"] <- "TS_1_7_1"
names(df3)[names(df3) == "TS_4_10_1"] <- "TS_1_8_1"
names(df3)[names(df3) == "TS_4_11_1"] <- "TS_1_9_1"
names(df3)[names(df3) == "TS_4_12_1"] <- "TS_1_10_1"
```


```{r}
#Biomet: using gap filled and not gap filled in the same column?

names(df1)[names(df1) == "SW_IN_F"] <- "SW_IN"
names(df1)[names(df1) == "LW_IN_F"] <- "LW_IN"
names(df1)[names(df1) == "VPD_F"] <- "VPD"
names(df1)[names(df1) == "TA_F"] <- "TA"


#removes unused biomet (delete?)
df1 <- select(df1, !all_of(names(df1)[grep("_F$", names(df1))]))

#Flux

names(df1)[names(df1) == "GPP_NT_VUT_REF"] <- "GPP_F"
names(df1)[names(df1) == "NEE_VUT_REF"] <- "FC_F"
names(df1)[names(df1) == "RECO_NT_VUT_REF"] <- "RECO"
names(df1)[names(df1) == "LE_F_MDS"] <- "LE"
names(df1)[names(df1) == "H_F_MDS"] <- "H"






df <- rbind.fill(df1, df3)

df$TIMESTAMP = df$TIMESTAMP_END


```

# Add Nighttime NEE data

```{r}

df <- df %>%
  mutate(FC_night = ifelse(SW_IN <= 0, FC, NA))

df <- df %>%
  mutate(FC_night_F = ifelse(SW_IN <= 0, FC_F, NA))

# # Plot the filtered vs. unfiltered CO2 Flux values to visualize nighttime data
# ggplot(data = df)+
#   geom_hline(yintercept = 0)+
#   geom_point(aes(TIMESTAMP,FC,col='Original'))+
#   geom_point(aes(TIMESTAMP,FC_night,col='Nighttime CO2 Flux'))+
#   scale_y_continuous(limits=c(-7,6))+
#   # scale_x_datetime(limits = as.POSIXct(c('2023-01-01','2023-12-01'),format="%F"))+
#   labs(y = "CO2 Flux", x = "Time") +
#   scale_color_manual(values=c('deeppink3','black'))

```



# Create Average Dataframe

```{r}

df$date = as.Date(df$TIMESTAMP_END)

date = unique(df$date)

#average entire dataframe with tighter threshold
df_avg = as.data.frame(date)
df_avg <- timeAverage(df, avg.time = "day", data.thresh = 50)

#average dataframe with lighter threshold to get good nighttime data coverage
df_avg_night = as.data.frame(date)
df_avg_night <- timeAverage(df, avg.time = "day", data.thresh = 10)

#add nighttime average data back into full dataset
df_avg$FC_night = df_avg_night$FC_night
df_avg$FC_night_F = df_avg_night$FC_night_F

rm(df_avg_night)



# #for viewing data coverage
# 
# 
# plot(df_avg$FC_night)
# 
# year_df <- function(df, year) {
#   df %>%
#     filter(format(date, "%Y") == as.character(year)) %>%
#     mutate(DOY = yday(date))
# }
# 
# df_avg_2023 <- year_df(df_avg, 2023)
# 
# summary(df_avg_2023)
# 
# plot(df_avg_2023$FC_night)
# 
# plot(df_avg_2023$TS_1_05_1, df_avg_2023$FC_night)


# plot(df_avg$date, df_avg$FC_F)
# plot(df_avg$date, df_avg$GPP_F)
# plot(df_avg$date, df_avg$RECO)
# plot(df_avg$date, df_avg$FC_night_F)


```


# Save Data

```{r}

write.csv(x = df,file = 'C:/Users/dtrangmoe/Documents/Churchill/Data/Churchill_Merged_CF1_CF3.csv',row.names = F,quote = F)

write.csv(x = df_avg,file = 'C:/Users/dtrangmoe/Documents/Churchill/Data/Churchill_Merged_Avg_CF1_CF3.csv',row.names = F,quote = F)

```